{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eecbb12",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "### 原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7108ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "# 120 * 5\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# 30 * 5\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cbafb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0            6.4         2.8          5.6         2.2        2\n",
       "1            5.0         2.3          3.3         1.0        1\n",
       "2            4.9         2.5          4.5         1.7        2\n",
       "3            4.9         3.1          1.5         0.1        0\n",
       "4            5.7         3.8          1.7         0.3        0\n",
       "..           ...         ...          ...         ...      ...\n",
       "115          5.5         2.6          4.4         1.2        1\n",
       "116          5.7         3.0          4.2         1.2        1\n",
       "117          4.4         2.9          1.4         0.2        0\n",
       "118          4.8         3.0          1.4         0.1        0\n",
       "119          5.5         2.4          3.7         1.0        1\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check case\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7eb305",
   "metadata": {},
   "source": [
    "### 构建数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea630ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集标签：120 * 1\n",
    "train_y = train.pop('Species')\n",
    "# 测试集标签：30 * 1\n",
    "test_y = test.pop('Species')\n",
    "# 训练样本 train: 120 * 4 , 测试样本 test: 30 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d544fbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6.4\n",
       "1      5.0\n",
       "2      4.9\n",
       "3      4.9\n",
       "4      5.7\n",
       "      ... \n",
       "115    5.5\n",
       "116    5.7\n",
       "117    4.4\n",
       "118    4.8\n",
       "119    5.5\n",
       "Name: SepalLength, Length: 120, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check case\n",
    "# train_y\n",
    "# train\n",
    "# train.keys()\n",
    "dict(train)['SepalLength']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2af642",
   "metadata": {},
   "source": [
    "## Estimator 使用\n",
    "### 创建输入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0247a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入函数\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # 将输入转换为数据集。\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # 如果在训练模式下混淆并重复数据。\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "# 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8eeb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义特征列\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae708941",
   "metadata": {},
   "source": [
    "### 分类器实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f01d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpklite7bd\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpklite7bd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1e3d7d84a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# 默认 \n",
    "## 构建一个拥有两个隐层，隐藏节点分别为 30 和 10 的深度神经网络。\n",
    "# classifier = tf.estimator.DNNClassifier(\n",
    "#     feature_columns=my_feature_columns,\n",
    "#     # 隐层所含结点数量分别为 30 和 10.\n",
    "#     hidden_units=[30, 10],\n",
    "#     # 模型必须从三个类别中做出选择。\n",
    "#     n_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724dda2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/iris', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1200, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1e3d7eb390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# 自定义 checkpoints\n",
    "## Checkpoints 设置\n",
    "my_checkpointing_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs = 20 * 60,\n",
    "    keep_checkpoint_max = 10\n",
    ")\n",
    "\n",
    "## 分类器\n",
    "# 构建一个拥有两个隐层，隐藏节点分别为 30 和 10 的深度神经网络。\n",
    "classifier_diy = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # 隐层所含结点数量分别为 30 和 10.\n",
    "    hidden_units=[30, 10],\n",
    "    # 模型必须从三个类别中做出选择。\n",
    "    n_classes=3,\n",
    "    model_dir = 'models/iris',\n",
    "    config=my_checkpointing_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b12ff",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25480d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into models/iris/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.8813686, step = 15001\n",
      "INFO:tensorflow:global_step/sec: 750.15\n",
      "INFO:tensorflow:loss = 5.848205, step = 15101 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 968.011\n",
      "INFO:tensorflow:loss = 5.6258526, step = 15201 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 964.656\n",
      "INFO:tensorflow:loss = 5.4370074, step = 15301 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.053\n",
      "INFO:tensorflow:loss = 6.0909038, step = 15401 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 957.757\n",
      "INFO:tensorflow:loss = 4.659221, step = 15501 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.93\n",
      "INFO:tensorflow:loss = 5.4505396, step = 15601 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 977.012\n",
      "INFO:tensorflow:loss = 7.0468054, step = 15701 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 967.123\n",
      "INFO:tensorflow:loss = 4.976233, step = 15801 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 905.936\n",
      "INFO:tensorflow:loss = 5.314427, step = 15901 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.387\n",
      "INFO:tensorflow:loss = 6.2797117, step = 16001 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 844.434\n",
      "INFO:tensorflow:loss = 6.344158, step = 16101 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 948.809\n",
      "INFO:tensorflow:loss = 5.3938413, step = 16201 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 959.426\n",
      "INFO:tensorflow:loss = 6.324178, step = 16301 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.323\n",
      "INFO:tensorflow:loss = 3.676012, step = 16401 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.68\n",
      "INFO:tensorflow:loss = 5.8066072, step = 16501 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 963.152\n",
      "INFO:tensorflow:loss = 4.9496756, step = 16601 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 973.812\n",
      "INFO:tensorflow:loss = 5.443478, step = 16701 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 971.612\n",
      "INFO:tensorflow:loss = 5.5347023, step = 16801 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.094\n",
      "INFO:tensorflow:loss = 7.234452, step = 16901 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 977.34\n",
      "INFO:tensorflow:loss = 5.545951, step = 17001 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 987.234\n",
      "INFO:tensorflow:loss = 6.124728, step = 17101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 972.184\n",
      "INFO:tensorflow:loss = 5.7189856, step = 17201 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.983\n",
      "INFO:tensorflow:loss = 5.66691, step = 17301 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1005.24\n",
      "INFO:tensorflow:loss = 5.696534, step = 17401 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 979.031\n",
      "INFO:tensorflow:loss = 5.763584, step = 17501 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: -212.735\n",
      "INFO:tensorflow:loss = 5.328248, step = 17601 (-0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 997.051\n",
      "INFO:tensorflow:loss = 5.5664854, step = 17701 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 963.745\n",
      "INFO:tensorflow:loss = 5.6495824, step = 17801 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 973.595\n",
      "INFO:tensorflow:loss = 5.8525534, step = 17901 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 992.946\n",
      "INFO:tensorflow:loss = 6.5196257, step = 18001 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 949.144\n",
      "INFO:tensorflow:loss = 4.9171414, step = 18101 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 994.656\n",
      "INFO:tensorflow:loss = 5.3143225, step = 18201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 985.085\n",
      "INFO:tensorflow:loss = 6.674757, step = 18301 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.714\n",
      "INFO:tensorflow:loss = 4.5533853, step = 18401 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 878.731\n",
      "INFO:tensorflow:loss = 6.7937713, step = 18501 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.14\n",
      "INFO:tensorflow:loss = 5.6596537, step = 18601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 860.624\n",
      "INFO:tensorflow:loss = 3.77215, step = 18701 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 991.545\n",
      "INFO:tensorflow:loss = 5.422345, step = 18801 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 987.411\n",
      "INFO:tensorflow:loss = 5.3277545, step = 18901 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 972.784\n",
      "INFO:tensorflow:loss = 5.5681124, step = 19001 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 957.422\n",
      "INFO:tensorflow:loss = 5.502225, step = 19101 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.218\n",
      "INFO:tensorflow:loss = 5.577734, step = 19201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.512\n",
      "INFO:tensorflow:loss = 5.085013, step = 19301 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 986.164\n",
      "INFO:tensorflow:loss = 6.1885448, step = 19401 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 989.79\n",
      "INFO:tensorflow:loss = 6.911217, step = 19501 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 968.946\n",
      "INFO:tensorflow:loss = 6.6471515, step = 19601 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.264\n",
      "INFO:tensorflow:loss = 4.4844713, step = 19701 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 978.903\n",
      "INFO:tensorflow:loss = 5.4597225, step = 19801 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 973.929\n",
      "INFO:tensorflow:loss = 6.4838066, step = 19901 (0.103 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into models/iris/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.2021027.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f1e3d7de4a8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型。\n",
    "classifier_diy.train(\n",
    "    # 输入函数\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    # 训练 steps 步后停止训练\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26086419",
   "metadata": {},
   "source": [
    "### 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "672e1e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-09-13T11:57:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2023-09-13-11:57:24\n",
      "INFO:tensorflow:Saving dict for global step 15000: accuracy = 0.96666664, average_loss = 0.18470596, global_step = 15000, loss = 5.5411787\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: models/iris/model.ckpt-15000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.96666664,\n",
       " 'average_loss': 0.18470596,\n",
       " 'loss': 5.5411787,\n",
       " 'global_step': 15000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型评估\n",
    "eval_result = classifier_diy.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55c6d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-09-13T11:57:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2023-09-13-11:57:53\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.96666664, average_loss = 0.21294494, global_step = 20000, loss = 6.388348\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: models/iris/model.ckpt-20000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.96666664,\n",
       " 'average_loss': 0.21294494,\n",
       " 'loss': 6.388348,\n",
       " 'global_step': 20000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型评估\n",
    "eval_result = classifier_diy.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "eval_result\n",
    "\n",
    "## 使用 tensorboard 来查看训练情况  http://127.0.0.1:6006\n",
    "### tensorboard --logdir models/iris --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c526a",
   "metadata": {},
   "source": [
    "### 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "876403c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "pred_dict: {'logits': array([ 51.02154 ,  43.691315, -67.36501 ], dtype=float32), 'probabilities': array([9.9934500e-01, 6.5499556e-04, 0.0000000e+00], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Setosa\" (99.9%), expected \"Setosa\"\n",
      "pred_dict: {'logits': array([ -4.486701,  10.502182, -12.314878], dtype=float32), 'probabilities': array([3.0932188e-07, 9.9999964e-01, 1.2321863e-10], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Versicolor\" (100.0%), expected \"Versicolor\"\n",
      "pred_dict: {'logits': array([-28.908272 ,  -3.4084837,  10.608127 ], dtype=float32), 'probabilities': array([6.8904157e-18, 8.1783031e-07, 9.9999917e-01], dtype=float32), 'class_ids': array([2]), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Virginica\" (100.0%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "# 由模型生成预测\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # 将输入转换为无标签数据集。\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier_diy.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))\n",
    "\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    print(\"pred_dict: {}\".format(pred_dict))\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a31c9",
   "metadata": {},
   "source": [
    "### 模型导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1652a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SepalLength': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None), 'SepalWidth': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None), 'PetalLength': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None), 'PetalWidth': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-20000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_models/iris/temp-b'1695035326'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'saved_models/iris/1695035326'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_dir = \"saved_models/iris\"\n",
    "\n",
    "\n",
    "feature_spec = tf.feature_column.make_parse_example_spec(my_feature_columns)\n",
    "print(feature_spec)\n",
    "#feature_spec = {'x': tf.FixedLenFeature([4],tf.float32)}\n",
    "\n",
    "# export_path = classifier_diy.export_saved_model(saved_model_dir,\n",
    "#     tf.estimator.export.build_raw_serving_input_receiver_fn(features=feature_spec))\n",
    "\n",
    "# export_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec)\n",
    "# export_input_fn = tf.contrib.learn.utils.build_parsing_serving_input_fn(feature_spec)\n",
    "# classifier_diy.export_savedmodel(saved_model_dir, export_input_fn)\n",
    "\n",
    "# 正常导出\n",
    "export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "classifier_diy.export_savedmodel(saved_model_dir, export_input_fn)\n",
    "    \n",
    "    \n",
    "# feature_spec = {'x': tf.FixedLenFeature([4],tf.float32)}\n",
    "\n",
    "# def serving_input_receiver_fn():\n",
    "#   serialized_tf_example = tf.placeholder(dtype=tf.string,\n",
    "#                                          shape=[None],\n",
    "#                                          name='input_tensors')\n",
    "#   receiver_tensors = {'inputs': serialized_tf_example}\n",
    "#   features = tf.parse_example(serialized_tf_example, feature_spec)\n",
    "#   return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
    "\n",
    "# export_path = classifier_diy.export_savedmodel(saved_model_dir, serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51b72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
